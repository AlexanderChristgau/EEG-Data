{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA analysis and pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import FastICA\n",
    "from coroica import CoroICA, UwedgeICA\n",
    "\n",
    "from scipy.special import comb\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#from utils import RFsLDA\n",
    "\n",
    "from timeit import default_timer\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of trials in each session\n",
    "n_ses = [273, 281, 270, 283, 270, 273, 262, 228, 262, 276, 219, 215, 271, 277, 264, 271, 237, 264]\n",
    "n_c = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data\n",
    "Classes= np.load('Classes.npy')\n",
    "Signals =np.load(\"Signals.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4696,) (4696, 21, 750) float32\n"
     ]
    }
   ],
   "source": [
    "print(Classes.shape, Signals.shape, Signals.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters for bandpass filtering\n",
    "lowcut = 8\n",
    "highcut = 30\n",
    "fs = 250 # sampling frequency\n",
    "order = 3\n",
    "nyq = 0.5 * fs\n",
    "low = lowcut / nyq\n",
    "high = highcut / nyq\n",
    "b, a = butter(order, [low, high], btype='band')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to sanitycheck classifyer on raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.log(np.var(Signals, axis = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovo', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(decision_function_shape='ovo')\n",
    "clf.fit(X_test, Classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4844548551959114"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts = clf.predict(X_test)\n",
    "np.mean(predicts==Classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Indices(persons):\n",
    "    ans = []\n",
    "    for p in persons:\n",
    "        a = sum(n_ses[:2*p])\n",
    "        b = sum(n_ses[:2*p+2])\n",
    "        ans += list(range(a,b))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_signal(arr):\n",
    "    x,y,z = arr.shape\n",
    "    a = np.stack(arr, axis = 1)\n",
    "    a = a.reshape((y, x*z))\n",
    "    return a.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_list = range(sum(n_ses))\n",
    "def Signals_pipeline(persons):\n",
    "    I = Indices(persons)\n",
    "    LeaveOut = list(set(N_list) - set(I))\n",
    "\n",
    "    ## Get signals and reshape\n",
    "    Signals1,Signals2 = Signals[I], Signals[LeaveOut]\n",
    "    return reshape_signal(Signals1),reshape_signal(Signals2), I, LeaveOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICA_METHODS(constrained=0, k=0):\n",
    "    return {\n",
    "        \"CoroICA\":CoroICA(partitionsize= int(20 * 200),\n",
    "                          max_iter =6000*(1-constrained) +3*k,\n",
    "                          n_components=n_c,\n",
    "                          groupsize = int(520*750),\n",
    "                          minimize_loss=False,\n",
    "                          condition_threshold=1000,\n",
    "                          #tol=1e-14,\n",
    "                          pairing='neighbouring'),\n",
    "        \"choiICA\": UwedgeICA(partitionsize= int(20 * 200),\n",
    "                             max_iter =1000*(1-constrained) +4*k,\n",
    "                             n_components=n_c,\n",
    "                             condition_threshold=1000,\n",
    "                             #tol=1e-14,\n",
    "                             instantcov=True,\n",
    "                             timelags=None),\n",
    "        \"FastICA\":FastICA(n_components=n_c,\n",
    "                          tol=0.00001,\n",
    "                          max_iter =(40*(1-constrained)+3*constrained+k)\n",
    "                         )\n",
    "    }\n",
    "def Classifier():\n",
    "    return {\n",
    "        \"SVM\": svm.SVC(decision_function_shape='ovo', kernel = \"linear\"),\n",
    "        \"RF\": RandomForestClassifier(n_estimators = 10000,max_depth = 5),\n",
    "        \"LDA\":LinearDiscriminantAnalysis(),\n",
    "        \"QDA\":QuadraticDiscriminantAnalysis(reg_param=0.1),\n",
    "        \"AdaBoost\":AdaBoostClassifier(svm.SVC(decision_function_shape='ovo', kernel = \"linear\"),\n",
    "                                      n_estimators=200),\n",
    "        \"MLP\": MLPClassifier(random_state=1, max_iter=10000),\n",
    "        \"RFsLDA\": RFsLDA()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICA_pipeline(method,Signals1,Signals2,I,LeaveOut,classifier = \"SVM\",\n",
    "                constrained=0,k=0):\n",
    "        ## Apply ICA\n",
    "        transformer = ICA_METHODS(constrained,k)[method]\n",
    "        start = default_timer()\n",
    "        X = transformer.fit_transform(Signals1)\n",
    "        Y = transformer.transform(Signals2)\n",
    "        end = default_timer()\n",
    "        X,Y = X.transpose(), Y.transpose()\n",
    "        X,Y = X.reshape((n_c, len(I), 750)),Y.reshape(n_c,len(N_list)-len(I),750)\n",
    "        \n",
    "        #Apply bandpass filters\n",
    "        Filt1,Filt2 = lfilter(b,a,X),lfilter(b,a,Y)\n",
    "\n",
    "        ## Extract bandpower features\n",
    "        Features1,Features2 = np.log(np.var(Filt1, axis = 2)),np.log(np.var(Filt2, axis = 2))\n",
    "        Features1,Features2 = Features1.transpose(),Features2.transpose()\n",
    "        \n",
    "        ## Fit Classifier and predict\n",
    "        clf = Classifier()[classifier]\n",
    "        clf.fit(Features1, Classes[I])\n",
    "\n",
    "        predicts = clf.predict(Features2)\n",
    "        return np.mean(predicts==Classes[LeaveOut]),end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Main_Pipeline(n_train=[8], max_iter = 5, echo = False,\n",
    "                  classifier = \"SVM\", n_subs=9):\n",
    "    df = pd.DataFrame(columns = [\"Accuracy\", \"Method\", \"n_train\", \"Time\"])    \n",
    "    for n in n_train:\n",
    "        cache = []\n",
    "        n_subsets = min(comb(n_subs,n,exact=True),max_iter)\n",
    "        for i in tqdm(np.random.permutation(list(combinations(range(n_subs),n)))[:n_subsets].tolist()):\n",
    "            cache.append(i)\n",
    "\n",
    "            S1,S2,I,L = Signals_pipeline(i)\n",
    "            if echo:\n",
    "                print(\"Finding ICA's for subset\", i)\n",
    "            try:\n",
    "                x1, x2 = ICA_pipeline(\"FastICA\",S1,S2,I,L,classifier)\n",
    "            except ValueError:\n",
    "                print(\"FastICA crashed\")\n",
    "                continue\n",
    "            else:\n",
    "                y1, y2 = ICA_pipeline(\"CoroICA\",S1,S2,I,L,classifier)\n",
    "                z1, z2 = ICA_pipeline(\"choiICA\",S1,S2,I,L,classifier)\n",
    "\n",
    "                df = df.append({\"Accuracy\":x1,\"Method\" : \"FastICA\",\"n_train\":n,\"Time\":x2},ignore_index=True)\n",
    "                df = df.append({\"Accuracy\":y1,\"Method\" : \"CoroICA\",\"n_train\":n,\"Time\":y2},ignore_index=True)\n",
    "                df = df.append({\"Accuracy\":z1,\"Method\":\"choiICA\",\"n_train\":n,\"Time\":z2},ignore_index=True)\n",
    "        print(cache)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try ICA on trained on subject 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sig1,Sig2, I, L = Signals_pipeline(range(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(415500, 21)\n"
     ]
    }
   ],
   "source": [
    "transformer = FastICA(n_components=n_c, tol=0.01,random_state=0)\n",
    "X1 = transformer.fit_transform(Sig1)\n",
    "print(X1.shape)\n",
    "X2 =  transformer.transform(Sig2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1,X2 = X1.transpose(), X2.transpose()\n",
    "X1,X2 = X1.reshape((n_c, len(I), 750)),X2.reshape(n_c,len(L),750)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bandpass filter and bandpower features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply bandpass filters\n",
    "Filt1,Filt2 = lfilter(b,a,X1),lfilter(b,a,X2)\n",
    "\n",
    "## Extract bandpower features\n",
    "Features1,Features2 = np.log(np.var(Filt1, axis = 2)),np.log(np.var(Filt2, axis = 2))\n",
    "Features1,Features2 = Features1.transpose(),Features2.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try classifying on ica's banpowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovo', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(decision_function_shape='ovo', kernel = \"linear\")\n",
    "clf.fit(Features1, Classes[I])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32617093191694835"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts = clf.predict(Features2)\n",
    "np.mean(predicts==Classes[L])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.1,\n",
       "                              store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = QuadraticDiscriminantAnalysis(reg_param=0.1)\n",
    "clf.fit(Features1, Classes[I])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.297682279092226"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts = clf.predict(Features2)\n",
    "np.mean(predicts==Classes[L])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Main_Pipeline(range(1,9),max_iter=30, classifier = \"SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "fig, ax = plt.subplots(figsize=(15, 6), sharex=True)\n",
    "ax = sns.violinplot(x=\"n_train\", y=\"Accuracy\", hue=\"Method\", inner = \"box\",\n",
    "                     palette=\"Set3\", cut=1, bw = 1.5,\n",
    "                     data=df,ax = ax)\n",
    "ax.set(xlabel='Number of training subjects', ylabel='Prediction accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6), sharex=True)\n",
    "ax = sns.lineplot(x=\"n_train\", y=\"Accuracy\", hue = \"Method\", estimator=np.median,\n",
    "                  palette=\"Set3\", err_kws = {\"alpha\": 0.3, \"lw\":2}, sizes = 3,\n",
    "                  **{\"fillstyle\":\"none\"},\n",
    "                  data=df1) #,style = \"Classifier\"\n",
    "ax.set(xlabel='Number of training subjects', ylabel='Prediction accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "g = sns.FacetGrid(df, col=\"n_train\", hue=\"Method\",col_wrap = 4,\n",
    "                  #subplot_kws=dict(projection='polar'), height=4.5,\n",
    "                  sharex=True, sharey=False)\n",
    "\n",
    "ax = g.map(sns.scatterplot, \"Time\", \"Accuracy\")\n",
    "'''ax.set(xlabel='Number of training subjects', \n",
    "       ylabel='Prediction accuracy',\n",
    "      )\n",
    "ax.set(xlim=(0, 75), ylim=(0.2,0.6))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax1 = plt.subplots(figsize=(15, 6), sharex=True)\n",
    "#ax1 = sns.catplot(x=\"n_train\", y=\"Accuracy\", hue=\"Method\",\n",
    "#                    data=df, kind=\"box\",fliersize = 1,whis=1, ax = ax1) #,, ,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timeconstrained pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Time_Pipeline(n_train=6,k_max = 15, max_iter = 5,classifier = \"SVM\", n_subs=9):\n",
    "    df = pd.DataFrame(columns = [\"Accuracy\", \"Method\", \"Time\", \"k\", \"Subset\"])    \n",
    "    cache = []\n",
    "    \n",
    "    n_subsets = min(comb(n_subs,n_train,exact=True),max_iter)\n",
    "    for i in tqdm(np.random.permutation(list(combinations(range(n_subs),n_train)))[:n_subsets].tolist()):\n",
    "        cache.append(i)\n",
    "\n",
    "        S1,S2,I,L = Signals_pipeline(i)\n",
    "        for k in tqdm(range(1,k_max)):\n",
    "            try:\n",
    "                x1, x2 = ICA_pipeline(\"FastICA\",S1,S2,I,L,classifier,1,k)\n",
    "            except ValueError:\n",
    "                print(\"FastICA crashed\")\n",
    "                continue\n",
    "            else:\n",
    "                y1, y2 = ICA_pipeline(\"CoroICA\",S1,S2,I,L,classifier,1,k)\n",
    "                z1, z2 = ICA_pipeline(\"choiICA\",S1,S2,I,L,classifier,1,k)\n",
    "                \n",
    "                subs = \"\".join([str(c) for c in i])\n",
    "                df = df.append({\"Accuracy\":x1,\"Method\":\"FastICA\",\"Time\":x2,\"k\":k,\"Subset\":subs},ignore_index=True)\n",
    "                df = df.append({\"Accuracy\":y1,\"Method\":\"CoroICA\",\"Time\":y2,\"k\":k,\"Subset\":subs},ignore_index=True)\n",
    "                df = df.append({\"Accuracy\":z1,\"Method\":\"choiICA\",\"Time\":z2,\"k\":k,\"Subset\":subs},ignore_index=True)            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Time_Pipeline(n_train=6,k_max = 20, max_iter=4, classifier = \"SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lmplot(y=\"Accuracy\", x=\"Time\",hue=\"Method\",\n",
    "                col_wrap = 2, col = \"Subset\",\n",
    "                lowess = True,\n",
    "                data=df)\n",
    "ax.set(xlabel='Time', \n",
    "       ylabel='Prediction accuracy',\n",
    "      )\n",
    "#ax.set(xlim=(0, 30), ylim=(0.1,0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "g = sns.FacetGrid(df, col=\"Subset\", hue=\"Method\",col_wrap = 2,\n",
    "                  #subplot_kws=dict(projection='polar'), height=4.5,\n",
    "                  sharex=True, sharey=False)\n",
    "\n",
    "ax = g.map(sns.lineplot, \"Time\", \"Accuracy\",lowess = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_pickle(\"Timed_RFLDA_REAL.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"SVM30rep.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Subset\"] = df[\"Subset\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df[\"n_train\"]==6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1[\"n_train\"] = pd.to_numeric(df1[\"n_train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax.savefig('Plots/TimeEXP.pdf', format = \"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.backends.backend_pdf\n",
    "\n",
    "def plot1(save=False):\n",
    "    pdf = matplotlib.backends.backend_pdf.PdfPages(\"Signalsplot.pdf\")\n",
    "    \n",
    "    \n",
    "    fig1, axs = plt.subplots(5,1,figsize=(12, 6),sharex = True)\n",
    "    #fig.tight_layout()\n",
    "    for ax, sig in zip(axs,[Signals[0,i,:] for i in range(5)]):\n",
    "        ax.plot(sig[:750])\n",
    "    fig1.suptitle('Raw signals', fontsize=16)\n",
    "    pdf.savefig(fig1)\n",
    "    \n",
    "    fig2, axs = plt.subplots(5,1,figsize=(12, 6),sharey =True,sharex=True)\n",
    "    #fig.tight_layout()\n",
    "    for ax, sig in zip(axs,[X1[0,i,:] for i in range(5)]):\n",
    "        ax.plot(sig[:750])\n",
    "    fig2.suptitle(\"Independent components\", fontsize=16)\n",
    "    pdf.savefig(fig2)\n",
    "    \n",
    "    fig3, axs = plt.subplots(5,1,figsize=(12, 6),sharey =True,sharex=True)\n",
    "    #fig.tight_layout()\n",
    "    for ax, sig in zip(axs,[Filt1[0,i,:] for i in range(5)]):\n",
    "        ax.plot(sig[:750])\n",
    "    fig3.suptitle(\"Filtered independent components\", fontsize=16)\n",
    "    if save:\n",
    "        pdf.savefig(fig3)\n",
    "    pdf.close()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
