{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA analysis and pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook accompanies a project on Independent Componennt Analysis (ICA) applied to electroencelographic data. Depends on \"Data Cleaning.ipynb\" and \"utils.py\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import FastICA\n",
    "from coroica import CoroICA, UwedgeICA\n",
    "\n",
    "from scipy.special import comb\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from utils import RFsLDA\n",
    "\n",
    "from timeit import default_timer\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of trials in each session\n",
    "n_ses = [273, 281, 270, 283, 270, 273, 262, 228, 262, 276, 219, 215, 271, 277, 264, 271, 237, 264]\n",
    "\n",
    "#Number of components. Should be 22 if data is not preprocessed with CAR.\n",
    "n_c = 21 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data\n",
    "Classes = np.load('Classes.npy')\n",
    "Signals = np.load(\"Signals.npy\")\n",
    "\n",
    "print(Classes.shape, Signals.shape, Signals.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup parameters for 8-30Hz bandpass filtering\n",
    "lowcut = 8\n",
    "highcut = 30\n",
    "fs = 250 # sampling frequency\n",
    "order = 3\n",
    "nyq = 0.5 * fs\n",
    "low = lowcut / nyq\n",
    "high = highcut / nyq\n",
    "b, a = butter(order, [low, high], btype='band')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try sanitycheck classification on raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.log(np.var(Signals, axis = 2)) #Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit classifier\n",
    "clf = svm.SVC(decision_function_shape='ovo')\n",
    "clf.fit(X_test, Classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get prediction accuracy\n",
    "predicts = clf.predict(X_test)\n",
    "np.mean(predicts==Classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define functions that will extract correct indicies for a particular train-test split.\n",
    "N_list = range(sum(n_ses))\n",
    "\n",
    "def Indices(persons):\n",
    "    ans = []\n",
    "    for p in persons:\n",
    "        a = sum(n_ses[:2*p])\n",
    "        b = sum(n_ses[:2*p+2])\n",
    "        ans += list(range(a,b))\n",
    "    return ans\n",
    "\n",
    "def reshape_signal(arr):\n",
    "    x,y,z = arr.shape\n",
    "    a = np.stack(arr, axis = 1)\n",
    "    a = a.reshape((y, x*z))\n",
    "    return a.transpose()\n",
    "\n",
    "def Signals_pipeline(persons):\n",
    "    I = Indices(persons)\n",
    "    LeaveOut = list(set(N_list) - set(I))\n",
    "\n",
    "    ## Get signals and reshape\n",
    "    Signals1,Signals2 = Signals[I], Signals[LeaveOut]\n",
    "    return reshape_signal(Signals1),reshape_signal(Signals2), I, LeaveOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize ICA methods and classifiers for experiments.\n",
    "\n",
    "def ICA_METHODS(constrained=0, k=0, eps=1e-14):\n",
    "    '''\n",
    "    Parameters \"constrained\" and \"k\" regulates the maximum number of itterations allowed\n",
    "    and used for the timeconstrained pipeline.\n",
    "    Parameter \"eps\" controls the tolerance and is used for tolerance pipeline.\n",
    "    \n",
    "    Returns ICA methods as instances of classess. \n",
    "    '''\n",
    "    return {\n",
    "        \"CoroICA\":CoroICA(partitionsize= int(20 * 200),\n",
    "                          max_iter =6000*(1-constrained) +2*k,\n",
    "                          n_components=n_c,\n",
    "                          groupsize = int(520*750),\n",
    "                          minimize_loss=False,\n",
    "                          condition_threshold=1000,\n",
    "                          tol=eps,\n",
    "                          pairing='neighbouring'),\n",
    "        \"choiICA\": UwedgeICA(partitionsize= int(20 * 200),\n",
    "                             max_iter =1000*(1-constrained) +3*k,\n",
    "                             n_components=n_c,\n",
    "                             condition_threshold=1000,\n",
    "                             tol=eps,\n",
    "                             instantcov=True,\n",
    "                             timelags=None),\n",
    "        \"FastICA\":FastICA(n_components=n_c,\n",
    "                          tol=0.00001,\n",
    "                          max_iter =(40*(1-constrained)+3*constrained+k)\n",
    "                         )\n",
    "    }\n",
    "\n",
    "\n",
    "def Classifier():\n",
    "    return {\n",
    "        \"SVM\": svm.SVC(decision_function_shape='ovo', kernel = \"linear\"),\n",
    "        \"RF\": RandomForestClassifier(n_estimators = 10000,max_depth = 5),\n",
    "        \"LDA\":LinearDiscriminantAnalysis(),\n",
    "        \"QDA\":QuadraticDiscriminantAnalysis(reg_param=0.1),\n",
    "        \"AdaBoost\":AdaBoostClassifier(svm.SVC(decision_function_shape='ovo', kernel = \"linear\"),\n",
    "                                      n_estimators=200),\n",
    "        \"MLP\": MLPClassifier(random_state=1, max_iter=10000),\n",
    "        \"RFsLDA\": RFsLDA()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ICA on the observed mixed signals for the training data and recover estimated source signals.\n",
    "\n",
    "def ICA_pipeline(method,Signals1,Signals2,I,LeaveOut,classifier = \"SVM\",\n",
    "                constrained=0,k=0,eps=1e-14):\n",
    "        ## Apply ICA\n",
    "        transformer = ICA_METHODS(constrained,k,eps)[method]\n",
    "        start = default_timer()  #Record start of timing\n",
    "        X = transformer.fit_transform(Signals1)\n",
    "        Y = transformer.transform(Signals2)\n",
    "        end = default_timer()    #Record end of timing\n",
    "        \n",
    "        X,Y = X.transpose(), Y.transpose()\n",
    "        X,Y = X.reshape((n_c, len(I), 750)),Y.reshape(n_c,len(N_list)-len(I),750)\n",
    "        \n",
    "        #Apply bandpass filters\n",
    "        Filt1,Filt2 = lfilter(b,a,X),lfilter(b,a,Y)\n",
    "\n",
    "        ## Extract bandpower features\n",
    "        Features1,Features2 = np.log(np.var(Filt1, axis = 2)),np.log(np.var(Filt2, axis = 2))\n",
    "        Features1,Features2 = Features1.transpose(),Features2.transpose()\n",
    "        \n",
    "        ## Fit Classifier and predict\n",
    "        clf = Classifier()[classifier]\n",
    "        clf.fit(Features1, Classes[I])\n",
    "\n",
    "        predicts = clf.predict(Features2)\n",
    "        return np.mean(predicts==Classes[LeaveOut]),end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Main_Pipeline(n_train=[8], max_iter = 5, echo = False,\n",
    "                  classifier = \"SVM\", n_subs=9):\n",
    "    df = pd.DataFrame(columns = [\"Accuracy\", \"Method\", \"n_train\", \"Time\"])    \n",
    "    for n in n_train:\n",
    "        cache = []\n",
    "        n_subsets = min(comb(n_subs,n,exact=True),max_iter)\n",
    "        for i in tqdm(np.random.permutation(list(combinations(range(n_subs),n)))[:n_subsets].tolist()):\n",
    "            cache.append(i)\n",
    "\n",
    "            S1,S2,I,L = Signals_pipeline(i)\n",
    "            if echo:\n",
    "                print(\"Finding ICA's for subset\", i)\n",
    "            try:\n",
    "                x1, x2 = ICA_pipeline(\"FastICA\",S1,S2,I,L,classifier) #Sometimes FastICA will crash.\n",
    "            except ValueError:\n",
    "                print(\"FastICA crashed\")\n",
    "                continue\n",
    "            else:\n",
    "                y1, y2 = ICA_pipeline(\"CoroICA\",S1,S2,I,L,classifier)\n",
    "                z1, z2 = ICA_pipeline(\"choiICA\",S1,S2,I,L,classifier)\n",
    "\n",
    "                df = df.append({\"Accuracy\":x1,\"Method\" : \"FastICA\",\"n_train\":n,\"Time\":x2},ignore_index=True)\n",
    "                df = df.append({\"Accuracy\":y1,\"Method\" : \"CoroICA\",\"n_train\":n,\"Time\":y2},ignore_index=True)\n",
    "                df = df.append({\"Accuracy\":z1,\"Method\":\"choiICA\",\"n_train\":n,\"Time\":z2},ignore_index=True)\n",
    "        print(cache)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try ICA on subject 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sig1,Sig2, I, L = Signals_pipeline(range(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = FastICA(n_components=n_c, tol=0.01,random_state=0)\n",
    "X1 = transformer.fit_transform(Sig1)\n",
    "print(X1.shape)\n",
    "X2 =  transformer.transform(Sig2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1,X2 = X1.transpose(), X2.transpose()\n",
    "X1,X2 = X1.reshape((n_c, len(I), 750)),X2.reshape(n_c,len(L),750)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bandpass filter and bandpower features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply bandpass filters\n",
    "Filt1,Filt2 = lfilter(b,a,X1),lfilter(b,a,X2)\n",
    "\n",
    "## Extract bandpower features\n",
    "Features1,Features2 = np.log(np.var(Filt1, axis = 2)),np.log(np.var(Filt2, axis = 2))\n",
    "Features1,Features2 = Features1.transpose(),Features2.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try classifying on ica's banpowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Classifier()[\"SVM\"]\n",
    "clf.fit(Features1, Classes[I])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = clf.predict(Features2)\n",
    "np.mean(predicts==Classes[L])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Classifier()[\"QDA\"]\n",
    "clf.fit(Features1, Classes[I])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = clf.predict(Features2)\n",
    "np.mean(predicts==Classes[L])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = Main_Pipeline(range(1,9),max_iter=30, classifier = \"SVM\")  #FastICA will give warnings of convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"SVM30rep.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots of main experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "fig, ax = plt.subplots(figsize=(15, 6), sharex=True)\n",
    "ax = sns.violinplot(x=\"n_train\", y=\"Accuracy\", hue=\"Method\", inner = \"box\",\n",
    "                     palette=\"Set3\", cut=1, bw = 1.5,\n",
    "                     data=df,ax = ax)\n",
    "ax.set(xlabel='Number of training subjects', ylabel='Prediction accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6), sharex=True)\n",
    "ax = sns.lineplot(x=\"n_train\", y=\"Accuracy\", hue = \"Method\", estimator=np.median,\n",
    "                  palette=\"Set3\", err_kws = {\"alpha\": 0.3, \"lw\":2}, sizes = 3,\n",
    "                  **{\"fillstyle\":\"none\"},\n",
    "                  data=df) \n",
    "ax.set(xlabel='Number of training subjects', ylabel='Prediction accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "g = sns.FacetGrid(df, col=\"n_train\", hue=\"Method\",col_wrap = 4,\n",
    "                  sharex=True, sharey=True)\n",
    "\n",
    "ax = g.map(sns.scatterplot, \"Time\", \"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-constrained experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Time_Pipeline(n_train=6,k_max = 15, n_sets = 5,classifier = \"SVM\", n_subs=9):\n",
    "    df = pd.DataFrame(columns = [\"Accuracy\", \"Method\", \"Time\", \"k\", \"Subset\"])    \n",
    "    cache = []\n",
    "    \n",
    "    n_subsets = min(comb(n_subs,n_train,exact=True),n_sets)\n",
    "    for i in tqdm(np.random.permutation(list(combinations(range(n_subs),n_train)))[:n_subsets].tolist()):\n",
    "        cache.append(i)\n",
    "\n",
    "        S1,S2,I,L = Signals_pipeline(i)\n",
    "        for k in tqdm(range(1,k_max)):\n",
    "            try:\n",
    "                x1, x2 = ICA_pipeline(\"FastICA\",S1,S2,I,L,classifier,1,k)\n",
    "            except ValueError:\n",
    "                print(\"FastICA crashed\")\n",
    "                continue\n",
    "            else:\n",
    "                y1, y2 = ICA_pipeline(\"CoroICA\",S1,S2,I,L,classifier,1,k)\n",
    "                z1, z2 = ICA_pipeline(\"choiICA\",S1,S2,I,L,classifier,1,k)\n",
    "                \n",
    "                subs = \"\".join([str(c) for c in i])\n",
    "                df = df.append({\"Accuracy\":x1,\"Method\":\"FastICA\",\"Time\":x2,\"k\":k,\"Subset\":subs},ignore_index=True)\n",
    "                df = df.append({\"Accuracy\":y1,\"Method\":\"CoroICA\",\"Time\":y2,\"k\":k,\"Subset\":subs},ignore_index=True)\n",
    "                df = df.append({\"Accuracy\":z1,\"Method\":\"choiICA\",\"Time\":z2,\"k\":k,\"Subset\":subs},ignore_index=True)            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Time_Pipeline(n_train=7,k_max = 30, n_sets=8, classifier = \"SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots of time-constrained experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lmplot(y=\"Accuracy\", x=\"Time\",hue=\"Method\",sharex=True, sharey=True,\n",
    "                col_wrap = 2, col = \"Subset\",\n",
    "                lowess = True,\n",
    "                data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.backends.backend_pdf\n",
    "\n",
    "def plot1(save=False):\n",
    "    pdf = matplotlib.backends.backend_pdf.PdfPages(\"Signalsplot.pdf\")\n",
    "    \n",
    "    \n",
    "    fig1, axs = plt.subplots(5,1,figsize=(12, 6),sharex = True)\n",
    "    #fig.tight_layout()\n",
    "    for ax, sig in zip(axs,[Signals[0,i,:] for i in range(5)]):\n",
    "        ax.plot(sig[:750])\n",
    "    fig1.suptitle('Raw signals', fontsize=16)\n",
    "    pdf.savefig(fig1)\n",
    "    \n",
    "    fig2, axs = plt.subplots(5,1,figsize=(12, 6),sharey =True,sharex=True)\n",
    "    #fig.tight_layout()\n",
    "    for ax, sig in zip(axs,[X1[0,i,:] for i in range(5)]):\n",
    "        ax.plot(sig[:750])\n",
    "    fig2.suptitle(\"Independent components\", fontsize=16)\n",
    "    pdf.savefig(fig2)\n",
    "    \n",
    "    fig3, axs = plt.subplots(5,1,figsize=(12, 6),sharey =True,sharex=True)\n",
    "    #fig.tight_layout()\n",
    "    for ax, sig in zip(axs,[Filt1[0,i,:] for i in range(5)]):\n",
    "        ax.plot(sig[:750])\n",
    "    fig3.suptitle(\"Filtered independent components\", fontsize=16)\n",
    "    if save:\n",
    "        pdf.savefig(fig3)\n",
    "    pdf.close()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot1() #Requires having run the codesnippets under \"Try ICA on subject 1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stopping_Pipeline(n_train=6,eps_max = 15, n_sets = 5,classifier = \"SVM\", n_subs=9):\n",
    "    df = pd.DataFrame(columns = [\"Accuracy\", \"Method\", \"Time\", \"tol\", \"Subset\"])    \n",
    "    cache = []\n",
    "    \n",
    "    n_subsets = min(comb(n_subs,n_train,exact=True),n_sets)\n",
    "    for i in tqdm(np.random.permutation(list(combinations(range(n_subs),n_train)))[:n_subsets].tolist()):\n",
    "        cache.append(i)\n",
    "\n",
    "        S1,S2,I,L = Signals_pipeline(i)\n",
    "        for l in tqdm(range(1,eps_max)):\n",
    "            y1, y2 = ICA_pipeline(\"CoroICA\",S1,S2,I,L,classifier,0,0,10**(-l))\n",
    "            subs = \"\".join([str(c) for c in i])\n",
    "            df = df.append({\"Accuracy\":y1,\"Method\":\"CoroICA\",\"Time\":y2,\n",
    "                            \"tol\":10**(-l),\"Subset\":subs},ignore_index=True)\n",
    "            y1, y2 = ICA_pipeline(\"choiICA\",S1,S2,I,L,classifier,0,0,10**(-l))\n",
    "            df = df.append({\"Accuracy\":y1,\"Method\":\"choiICA\",\"Time\":y2,\n",
    "                            \"tol\":10**(-l),\"Subset\":subs},ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Stopping_Pipeline(n_train=4,eps_max = 14, n_sets=40, classifier = \"SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"-log(tol)\"] = -np.log(df[\"tol\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of tolerance experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6), sharex=True)\n",
    "ax = sns.lineplot(x=\"-log(tol)\", y=\"Accuracy\", sort = False,\n",
    "                  hue = \"Method\",\n",
    "                  palette=\"Set2\", err_kws = {\"alpha\": 0.3, \"lw\":2}, sizes = 3,\n",
    "                  **{\"fillstyle\":\"none\"},\n",
    "                  data=df) \n",
    "ax.set(xlabel='- log(Tolerance)', ylabel='Prediction accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
